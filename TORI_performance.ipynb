{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install EbookLib"
      ],
      "metadata": {
        "id": "TstqJAar_wHE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bb6b04e-d3da-4f99-901c-99948e584603"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting EbookLib\n",
            "  Downloading EbookLib-0.18.tar.gz (115 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/115.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.5/115.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from EbookLib) (4.9.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from EbookLib) (1.16.0)\n",
            "Building wheels for collected packages: EbookLib\n",
            "  Building wheel for EbookLib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for EbookLib: filename=EbookLib-0.18-py3-none-any.whl size=38778 sha256=c2188f09b63a0dac6b42b3aca872b0eaf5c707c9f3e05c72a6a6a4bfaff31b24\n",
            "  Stored in directory: /root/.cache/pip/wheels/0f/38/cc/a3728bb72a315d9d8766fb71d362136372066fc25ad838f8fa\n",
            "Successfully built EbookLib\n",
            "Installing collected packages: EbookLib\n",
            "Successfully installed EbookLib-0.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import ebooklib\n",
        "from ebooklib import epub"
      ],
      "metadata": {
        "id": "MGYOr2UH_myd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "oTEsAmnzV8af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d04b0ea5-ddb9-4b16-d6ed-4d9c702baa46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to your EPUB file in Google Drive\n",
        "#epub_path = '/content/drive/My Drive/TORI_dataset/A_roomtour.epub'\n",
        "#epub_path = '/content/drive/My Drive/TORI_dataset/alice_wonderland.epub'\n",
        "#epub_path = '/content/drive/My Drive/TORI_dataset/enchanted_april.epub'\n",
        "#epub_path = '/content/drive/My Drive/TORI_dataset/Gatsby.epub'\n",
        "epub_path = '/content/drive/My Drive/TORI_dataset/blue_castle.epub'\n",
        "#epub_path = '/content/drive/My Drive/TORI_dataset/little_woman.epub'\n",
        "\n",
        "# Read the EPUB file\n",
        "book = epub.read_epub(epub_path)"
      ],
      "metadata": {
        "id": "6e7uVT-YnO5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_valid(epub_book):\n",
        "    \"\"\"Validates the structure of an EPUB book.\"\"\"\n",
        "    if not epub_book.toc:\n",
        "        print('Table of content is missing')\n",
        "        return False\n",
        "    if not epub_book.spine:\n",
        "        print('Spine is missing')\n",
        "        return False\n",
        "\n",
        "    # Check for stylesheets\n",
        "    stylesheets = [item for item in epub_book.get_items_of_type(ebooklib.ITEM_STYLE)]\n",
        "    if len(stylesheets) == 0:\n",
        "        print('No stylesheets')\n",
        "        return False\n",
        "\n",
        "    # Ensure chapters are not empty\n",
        "    for item in epub_book.spine:\n",
        "        if isinstance(item, epub.EpubHtml):\n",
        "            if not item.content.strip():\n",
        "                print(f\"Invalid book: Chapter '{item.get_id()}' is empty.\")\n",
        "                return False\n",
        "\n",
        "    return True"
      ],
      "metadata": {
        "id": "jP7OI5tX5R4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if is_valid(book):\n",
        "    print(\"The EPUB book is valid.\")\n",
        "else:\n",
        "    print(\"The EPUB book is not valid.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x66Vuu-J5SN7",
        "outputId": "246c9e7d-840a-421c-dcf4-32c43745b491"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The EPUB book is valid.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chapter_to_str(chapter):\n",
        "    \"\"\"Converts a chapter object into a string, filtering out non-textual elements.\"\"\"\n",
        "    soup = BeautifulSoup(chapter.get_body_content(), 'html.parser')\n",
        "    # Filtering out script and style elements\n",
        "    for script_or_style in soup([\"script\", \"style\"]):\n",
        "        script_or_style.decompose()\n",
        "    text = ' '.join(para.get_text(strip=True) for para in soup.find_all('p'))\n",
        "    return text"
      ],
      "metadata": {
        "id": "pYYfmktobcPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_wrapper(id):\n",
        "    \"\"\"\n",
        "    Determine if the item is the Gutenberg cover wrapper\n",
        "    \"\"\"\n",
        "    patterns = [\n",
        "        r'coverpage',\n",
        "        r'wrapper'\n",
        "    ]\n",
        "\n",
        "    return any(re.search(pattern, id, re.IGNORECASE) for pattern in patterns)"
      ],
      "metadata": {
        "id": "t1wkICuJbhbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_gutenberg_intro(item_content):\n",
        "    \"\"\"\n",
        "    Function to determine if the part of the content is Gutenberg introduction.\n",
        "    \"\"\"\n",
        "    # Pattern matching common Gutenberg intro phrases\n",
        "    patterns = [\n",
        "        r'Project Gutenberg',\n",
        "        r'\\bEBook\\b',\n",
        "        r'\\blicense\\b',\n",
        "        r'eBook or online at',\n",
        "        r'This eBook is for the use of'\n",
        "    ]\n",
        "    return any(re.search(pattern, item_content, re.IGNORECASE) for pattern in patterns)"
      ],
      "metadata": {
        "id": "ucIOZjr0brn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "for spine_item in book.spine:\n",
        "    item_id = spine_item[0] if isinstance(spine_item, tuple) else spine_item\n",
        "    item = book.get_item_with_id(item_id)\n",
        "\n",
        "    if isinstance(item, epub.EpubHtml) and not is_wrapper(item.get_id()):\n",
        "        chapter_text = chapter_to_str(item)\n",
        "        if chapter_text.strip():  # Check if the extracted text is not just whitespace\n",
        "            print(f\"Chapter ID: {item.get_id()}\\nText:\\n{chapter_text[:500]}...\\n\")\n",
        "        else:\n",
        "            print(f\"Chapter ID: {item.get_id()} contains no readable content.\")"
      ],
      "metadata": {
        "id": "s3SvntI6bxOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_chapters = []\n",
        "\n",
        "for spine_item in book.spine:\n",
        "    item_id = spine_item[0] if isinstance(spine_item, tuple) else spine_item\n",
        "    item = book.get_item_with_id(item_id)\n",
        "    if isinstance(item, epub.EpubHtml) and not is_wrapper(item.get_id()):\n",
        "        chapter_text = chapter_to_str(item)\n",
        "        if chapter_text.strip():\n",
        "            filtered_chapters.append(chapter_text)\n",
        "            print(f\"Content from Item ID: {item.get_id()} added.\")\n",
        "        else:\n",
        "            print(f\"Item ID: {item.get_id()} contains no readable content.\")\n",
        "    else:\n",
        "        print(f\"Item ID: {item.get_id()} skipped as non-content.\")\n"
      ],
      "metadata": {
        "id": "3y_SdPqaFKJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of filtered chapters:\", len(filtered_chapters))\n",
        "for chapter in filtered_chapters[:3]:\n",
        "    print(chapter[:500], \"...\")  # Print the first 500 characters of each chapter for review\n"
      ],
      "metadata": {
        "id": "Ix-7K43lN2qh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_text = \"\\n\\n\".join(filtered_chapters)  # Join all chapters, separated by two newlines"
      ],
      "metadata": {
        "id": "qPzcu6w2N-NO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = '/content/drive/My Drive/TORI_dataset/TORI_Book_blue_castle.txt'\n",
        "\n",
        "with open(output_path, 'w', encoding='utf-8') as file:\n",
        "    file.write(combined_text)"
      ],
      "metadata": {
        "id": "uKoj88VuOBAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BookNLP"
      ],
      "metadata": {
        "id": "adE25gXugnoC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install booknlp"
      ],
      "metadata": {
        "id": "AB8lPnyYgs4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "id": "apB7yIpogwKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from booknlp.booknlp import BookNLP\n",
        "# Model parameters\n",
        "model_params = {\n",
        "    \"pipeline\": \"entity,quote,supersense,event,coref\",\n",
        "    \"model\": \"big\"\n",
        "}\n",
        "# Initialize BookNLP with language and model parameters\n",
        "booknlp = BookNLP(\"en\", model_params)\n",
        "# Input file to process\n",
        "input_file = \"/content/drive/My Drive/TORI_dataset/TORI_Book_blue_castle.txt\"\n",
        "# Output directory to store resulting files\n",
        "output_directory = \"/content/drive/My Drive/booknlp_output/TORI_blue_castle_BNLP\"\n",
        "# Identifier for output files\n",
        "book_id = \"TORI_blue_castle\"\n",
        "# Process the input file\n",
        "booknlp.process(input_file, output_directory, book_id)"
      ],
      "metadata": {
        "id": "yOusbfwugpzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "DT4eMKUEh8SJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def proc(filename):\n",
        "    full_path = f'/content/drive/My Drive/{filename}'\n",
        "\n",
        "    with open(full_path) as file:\n",
        "        data = json.load(file)\n",
        "    return data"
      ],
      "metadata": {
        "id": "sWUAU2jVh9tk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = proc(\"booknlp_output/TORI_little_woman_BNLP/TORI_blue_castle.book\")"
      ],
      "metadata": {
        "id": "2t-9Gl6XiD0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_counter_from_dependency_list(dep_list):\n",
        "    counter=Counter()\n",
        "    for token in dep_list:\n",
        "        term=token[\"w\"]\n",
        "        tokenGlobalIndex=token[\"i\"]\n",
        "        counter[term]+=1\n",
        "    return counter"
      ],
      "metadata": {
        "id": "k5Be6D73iYfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for character in data[\"characters\"]:\n",
        "    possCounter=Counter()\n",
        "\n",
        "    agentList=character[\"agent\"]\n",
        "    patientList=character[\"patient\"]\n",
        "    possList=character[\"poss\"]\n",
        "    modList=character[\"mod\"]\n",
        "\n",
        "    character_id=character[\"id\"]\n",
        "    count=character[\"count\"]\n",
        "\n",
        "    referential_gender_distribution=referential_gender_prediction=\"unknown\"\n",
        "\n",
        "    if character[\"g\"] is not None and character[\"g\"] != \"unknown\":\n",
        "        referential_gender_distribution=character[\"g\"][\"inference\"]\n",
        "        referential_gender=character[\"g\"][\"argmax\"]\n",
        "\n",
        "    mentions=character[\"mentions\"]\n",
        "    proper_mentions=mentions[\"proper\"]\n",
        "    max_proper_mention=\"\"\n",
        "\n",
        "    # print out the characters with proper names, along with their syntactic information\n",
        "    if len(mentions[\"proper\"]) > 0:\n",
        "        max_proper_mention=mentions[\"proper\"][0][\"n\"]\n",
        "\n",
        "        print(character_id, count, max_proper_mention, referential_gender)\n",
        "\n",
        "        print()\n",
        "        printTop=20\n",
        "        for k, v in get_counter_from_dependency_list(possList).most_common(printTop):\n",
        "            print(\"\\tposs\\t%s %s\" % (v,k))\n",
        "        print()\n",
        "        for k, v in get_counter_from_dependency_list(agentList).most_common(printTop):\n",
        "            print(\"\\tagent\\t%s %s\" % (v,k))\n",
        "        print()\n",
        "        for k, v in get_counter_from_dependency_list(patientList).most_common(printTop):\n",
        "            print(\"\\tpatient\\t%s %s\" % (v,k))\n",
        "        print()\n",
        "        for k, v in get_counter_from_dependency_list(modList).most_common(printTop):\n",
        "            print(\"\\tmod\\t%s %s\" % (v,k))\n",
        "        print()"
      ],
      "metadata": {
        "id": "OjVrA7eeicAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oAMP393UiWDM"
      }
    }
  ]
}